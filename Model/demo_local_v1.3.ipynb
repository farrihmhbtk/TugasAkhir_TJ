{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cells below is for preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Ada', 'gak', 'sih', 'yang', 'punya', 'keinginan', 'aneh', 'kayak', 'saya', '?', 'Pengen', 'kerja', 'di', 'pt_transjakarta', 'sejak', 'pelayanannya', 'sebagus', 'itu', '.', 'Padahal', 'saya', 'udah', 'punya', 'pekerjaan', 'tetap', '.']\n",
      "target: (15, 15)\n",
      "opinion: (16, 17)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['pt_transjakarta', 'TERIMA', 'KASIH', 'semoga', 'bis2', 'yg', 'lain', 'juga', 'secara', 'berkala', 'bisa', 'ttp', 'dibersihkan', 'utk', 'mencegah', 'keluhan2', 'lagi', 'kedepannya']\n",
      "target: (0, 0)\n",
      "opinion: (1, 2)\n",
      "label: LabelEnum.positive\n",
      "target: (4, 4)\n",
      "opinion: (10, 12)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['Untung', 'busway', 'ac', 'nya', 'adem']\n",
      "target: (2, 2)\n",
      "opinion: (4, 4)\n",
      "label: LabelEnum.positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Data Exploration\n",
    "data_name = \"TJ v1.5 - v1.0.2\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from data_utils import Data\n",
    "\n",
    "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "data = Data.load_from_full_path(path)\n",
    "\n",
    "for s in data.sentences[:3]:\n",
    "    print(\"tokens:\", s.tokens)\n",
    "    for t in s.triples:\n",
    "        print(\"target:\", (t.t_start, t.t_end))\n",
    "        print(\"opinion:\", (t.o_start, t.o_end))\n",
    "        print(\"label:\", t.label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Define URL and file names\n",
    "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
    "data_name = \"14lap\"  # Replace with the correct name\n",
    "url = template.format(data_name)\n",
    "model_tar = Path(url).name\n",
    "model_dir = Path(url).stem\n",
    "\n",
    "# # Step 1: Download the file\n",
    "# print(\"Downloading the file...\")\n",
    "# with open(model_tar, \"wb\") as f:\n",
    "#     response = requests.get(url, stream=True)\n",
    "#     if response.status_code == 200:\n",
    "#         for chunk in response.iter_content(chunk_size=8192):\n",
    "#             f.write(chunk)\n",
    "# print(\"Download complete.\")\n",
    "\n",
    "# # Step 2: Extract the file\n",
    "# print(\"Extracting the file...\")\n",
    "# with tarfile.open(model_tar, \"r\") as tar:\n",
    "#     tar.extractall(model_dir)\n",
    "# print(f\"Extraction complete. Files are in '{model_dir}' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar\n",
      "tj2-seed_4\n",
      "aste/data/triplet_data/tj_2/train.txt\n",
      "root=WindowsPath('aste/data/triplet_data/tj_2') data_split=<SplitEnum.train: 'train'> sentences=[Sentence(tokens=['Supir', 'bus', 'Transjakarta', 'sangat', 'ramah', 'dalam', 'melayani', 'penumpang', 'berkebutuhan', 'khusus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=3, o_end=4, t_start=0, t_end=1, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Waktu', 'tunggu', 'di', 'halte', 'Harmoni', 'terlalu', 'lama', 'dan', 'tidak', 'ada', 'informasi', 'kedatangan', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=8, o_end=10, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sangat', 'nyaman', 'dengan', 'kursi', 'empuk', 'dan', 'AC', 'yang', 'dingin.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=3, o_end=4, t_start=0, t_end=1, label=<LabelEnum.positive: 'POS'>), SentimentTriple(o_start=6, o_end=7, t_start=0, t_end=1, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'kebersihan', 'bus', 'yang', 'kurang', 'terjaga,', 'terutama', 'di', 'lantai', 'bawah.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=10, o_end=12, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Pelayanan', 'petugas', 'di', 'halte', 'Bundaran', 'HI', 'sangat', 'ramah', 'dan', 'informatif.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=6, o_end=7, t_start=3, t_end=4, label=<LabelEnum.positive: 'POS'>), SentimentTriple(o_start=9, o_end=10, t_start=3, t_end=4, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'aman', 'menggunakan', 'Transjakarta', 'karena', 'ada', 'petugas', 'keamanan', 'di', 'setiap', 'halte.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>), SentimentTriple(o_start=10, o_end=12, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'sering', 'penuh', 'pada', 'jam', 'sibuk,', 'membuat', 'penumpang', 'tidak', 'nyaman.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=7, o_end=8, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'suka', 'rute', 'Transjakarta', 'yang', 'lengkap', 'dan', 'terintegrasi', 'dengan', 'moda', 'transportasi', 'lain.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.positive: 'POS'>), SentimentTriple(o_start=9, o_end=11, t_start=2, t_end=3, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Keterlambatan', 'bus', 'sering', 'terjadi,', 'terutama', 'pada', 'jam', 'sibuk.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=3, o_end=4, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Fasilitas', 'di', 'halte', 'Sudirman', 'cukup', 'lengkap,', 'termasuk', 'toilet', 'dan', 'musala.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=9, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'tidak', 'puas', 'dengan', 'ketersediaan', 'bus', 'pada', 'malam', 'hari,', 'sering', 'kali', 'harus', 'menunggu', 'lama.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=10, o_end=12, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'memiliki', 'desain', 'yang', 'modern', 'dan', 'menarik.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'Wi-Fi', 'gratis', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Kota', 'kurang', 'terjaga,', 'sampah', 'berserakan', 'di', 'mana-mana.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'senang', 'dengan', 'adanya', 'aplikasi', 'Transjakarta', 'yang', 'memudahkan', 'pembayaran.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'tepat', 'waktu,', 'membuat', 'penumpang', 'kesal.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=7, o_end=8, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'lansia', 'dan', 'disabilitas.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>), SentimentTriple(o_start=10, o_end=12, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Fasilitas', 'parkir', 'di', 'halte', 'Pondok', 'Indah', 'cukup', 'luas', 'dan', 'aman.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=9, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'kualitas', 'AC', 'di', 'beberapa', 'bus', 'yang', 'tidak', 'dingin.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'suka', 'dengan', 'adanya', 'layanan', 'Transjakarta', '24', 'jam', 'untuk', 'rute', 'tertentu.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'terlalu', 'penuh', 'pada', 'akhir', 'pekan,', 'membuat', 'penumpang', 'tidak', 'nyaman.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>), SentimentTriple(o_start=7, o_end=8, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'aman', 'dengan', 'adanya', 'CCTV', 'di', 'dalam', 'bus', 'dan', 'halte.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Ketersediaan', 'bus', 'pada', 'pagi', 'hari', 'sangat', 'membantu', 'para', 'pekerja.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Saya', 'tidak', 'puas', 'dengan', 'kebersihan', 'toilet', 'di', 'halte', 'Grogol.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'senang', 'dengan', 'adanya', 'layanan', 'bus', 'gratis', 'untuk', 'pelajar', 'dan', 'mahasiswa.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'memiliki', 'tempat', 'duduk', 'yang', 'cukup.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'wanita', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Senayan', 'cukup', 'baik,', 'tetapi', 'sampah', 'masih', 'terlihat', 'di', 'beberapa', 'sudut.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'ketersediaan', 'bus', 'pada', 'hari', 'libur,', 'sering', 'kali', 'harus', 'menunggu', 'lama.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'suka', 'dengan', 'adanya', 'layanan', 'Transjakarta', 'yang', 'terintegrasi', 'dengan', 'MRT', 'dan', 'LRT.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'memiliki', 'AC', 'yang', 'berfungsi', 'dengan', 'baik.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'ibu', 'hamil', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Blok', 'M', 'cukup', 'terjaga,', 'tetapi', 'masih', 'ada', 'sampah', 'di', 'beberapa', 'area.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'ketersediaan', 'bus', 'pada', 'malam', 'hari,', 'sering', 'kali', 'harus', 'menunggu', 'lama.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'senang', 'dengan', 'adanya', 'layanan', 'Transjakarta', 'yang', 'ramah', 'lingkungan.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'memiliki', 'tempat', 'duduk', 'yang', 'cukup', 'untuk', 'penumpang.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'lansia', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Kuningan', 'cukup', 'baik,', 'tetapi', 'masih', 'ada', 'sampah', 'di', 'beberapa', 'sudut.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'ketersediaan', 'bus', 'pada', 'hari', 'libur,', 'sering', 'kali', 'harus', 'menunggu', 'lama.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'suka', 'dengan', 'adanya', 'layanan', 'Transjakarta', 'yang', 'terintegrasi', 'dengan', 'MRT', 'dan', 'LRT.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'memiliki', 'AC', 'yang', 'berfungsi', 'dengan', 'baik.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'ibu', 'hamil', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Blok', 'M', 'cukup', 'terjaga,', 'tetapi', 'masih', 'ada', 'sampah', 'di', 'beberapa', 'area.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[]), Sentence(tokens=['Saya', 'kecewa', 'dengan', 'ketersediaan', 'bus', 'pada', 'malam', 'hari,', 'sering', 'kali', 'harus', 'menunggu', 'lama.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'senang', 'dengan', 'adanya', 'layanan', 'Transjakarta', 'yang', 'ramah', 'lingkungan.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Bus', 'Transjakarta', 'sering', 'kali', 'tidak', 'memiliki', 'tempat', 'duduk', 'yang', 'cukup', 'untuk', 'penumpang.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=4, o_end=5, t_start=0, t_end=1, label=<LabelEnum.negative: 'NEG'>)], spans=[]), Sentence(tokens=['Saya', 'merasa', 'nyaman', 'dengan', 'adanya', 'tempat', 'duduk', 'khusus', 'lansia', 'di', 'dalam', 'bus.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=7, o_end=8, t_start=4, t_end=5, label=<LabelEnum.positive: 'POS'>)], spans=[]), Sentence(tokens=['Kebersihan', 'di', 'halte', 'Kuningan', 'cukup', 'baik,', 'tetapi', 'masih', 'ada', 'sampah', 'di', 'beberapa', 'sudut.'], pos=[], weight=1, id=0, is_labeled=True, triples=[SentimentTriple(o_start=5, o_end=6, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>), SentimentTriple(o_start=8, o_end=10, t_start=2, t_end=3, label=<LabelEnum.neutral: 'NEU'>)], spans=[])] full_path='aste/data/triplet_data/tj_2/train.txt' num_instances=-1 opinion_offset=3 is_labeled=False\n"
     ]
    }
   ],
   "source": [
    "print(model_tar)\n",
    "print(model_dir)\n",
    "print(path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for Self-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gunakan SpanModel Anda untuk memberi pre-annotasi,\n",
    "lalu simpan output sebagai JSON array yang bisa langsung\n",
    "di-import ke Label Studio (Upload tasks ▸ JSON).\n",
    "\"\"\"\n",
    "\n",
    "import json, uuid\n",
    "from pathlib import Path\n",
    "from wrapper import SpanModel           # ← dari repo ASTE Anda\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "\n",
    "# --------------------- konfigurasi -----------------------\n",
    "MODEL_DIR  = \"outputs/TJ - Overall Dataset/seed_4 (baseline self_training)\"\n",
    "RAW_TXT    = \"self_training/batch 1.txt\"            # satu tweet per baris\n",
    "OUT_FILE   = \"self_training/batch 1.json\"     # **JSON array!**\n",
    "LABELS     = {\"POS\": \"sent:POS\", \"NEU\": \"sent:NEU\", \"NEG\": \"sent:NEG\"}\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "model = SpanModel(save_dir=MODEL_DIR, random_seed=0)\n",
    "\n",
    "def predict(text: str):\n",
    "    \"\"\"Jalankan SpanModel dan kembalikan (tokens, triples).\"\"\"\n",
    "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False,\n",
    "                    weight=1, id=0)\n",
    "    tmp_in, tmp_out = \"_tmp_in.txt\", \"_tmp_out.txt\"\n",
    "    Data(root=Path(), data_split=SplitEnum.test, sentences=[sent]).save_to_path(tmp_in)\n",
    "    model.predict(tmp_in, tmp_out)\n",
    "    new_sent = Data.load_from_full_path(tmp_out).sentences[0]\n",
    "    return new_sent.tokens, new_sent.triples\n",
    "\n",
    "tasks = []\n",
    "task_id = 0\n",
    "\n",
    "with open(RAW_TXT, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        tokens, triples = predict(text)\n",
    "        results = []\n",
    "\n",
    "        # buat span & relation result\n",
    "        for t in triples:\n",
    "            # span Aspect\n",
    "            asp_id = str(uuid.uuid4())[:10]\n",
    "            results.append({\n",
    "                \"id\": asp_id,\n",
    "                \"from_name\": \"label\",\n",
    "                \"to_name\": \"tweet_text\",\n",
    "                \"type\": \"labels\",\n",
    "                \"origin\": \"model\",\n",
    "                \"value\": {\n",
    "                    \"start\": len(\" \".join(tokens[:t.t_start])),\n",
    "                    \"end\": len(\" \".join(tokens[:t.t_end+1])),\n",
    "                    \"text\": \" \".join(tokens[t.t_start:t.t_end+1]),\n",
    "                    \"labels\": [\"aspect\"]\n",
    "                }\n",
    "            })\n",
    "\n",
    "            # span Opinion\n",
    "            op_id  = str(uuid.uuid4())[:10]\n",
    "            results.append({\n",
    "                \"id\": op_id,\n",
    "                \"from_name\": \"label\",\n",
    "                \"to_name\": \"tweet_text\",\n",
    "                \"type\": \"labels\",\n",
    "                \"origin\": \"model\",\n",
    "                \"value\": {\n",
    "                    \"start\": len(\" \".join(tokens[:t.o_start])),\n",
    "                    \"end\": len(\" \".join(tokens[:t.o_end+1])),\n",
    "                    \"text\": \" \".join(tokens[t.o_start:t.o_end+1]),\n",
    "                    \"labels\": [\"opinion\"]\n",
    "                }\n",
    "            })\n",
    "\n",
    "            # relation Aspect ↔ Opinion\n",
    "            results.append({\n",
    "                \"from_id\": asp_id,\n",
    "                \"to_id\":   op_id,\n",
    "                \"type\":    \"relation\",\n",
    "                \"direction\": \"right\",\n",
    "                \"labels\":  [LABELS[t.label.value]]\n",
    "            })\n",
    "\n",
    "        # satu objek = satu task LS\n",
    "        task_id += 1\n",
    "        tasks.append({\n",
    "            \"id\": task_id,\n",
    "            \"data\": {\n",
    "                \"cleaned_full_text\": text   # sesuaikan dgn <Text... value=\"$cleaned_full_text\"/>\n",
    "            },\n",
    "            \"predictions\": [{\n",
    "                \"model_version\": \"spanaste_v1\",\n",
    "                \"result\": results\n",
    "            }]\n",
    "        })\n",
    "\n",
    "# ----------- simpan JSON array -----------\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tasks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅  {len(tasks)} tasks tertulis ke {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cells are for testing the model with our own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tar = \"model.tar\"\n",
    "model_dir = \"outputs/Variasi Dataset/single word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488,
     "referenced_widgets": [
      "f61ea767ae064779b77f7d206a90b765",
      "382e7815e6314a798943a7f71eab1dbd",
      "b3f970d5f20748d091d13d1d37e712e4",
      "3c925c25029e4e5a9515b525a819cb31",
      "17148c3a40ae4572923f16f249179b9b",
      "9cc1d9231ee34d33b65a88c4de3b213f",
      "9afa9b48d00748739422b2e32763e57d",
      "f6d16c6d56974ec88f55333b65e0f16a",
      "e776ac7bd605497395d6cf45648c46e0",
      "87d171d5ff4d48bea3781c4185c53cd3",
      "ac44150d1166470f944a1d0effeae80b",
      "916c3c664f2348b5b608c368090945ac",
      "f00d08843e1a4e9e911a8d9fd11f04d1",
      "de26b5b4f1be42cba2951f528f7715ba",
      "d5d290cde75d463ba7b9b220eed79ca7",
      "e30953017bae40849979501dbb4647bc",
      "08b2e55d6325474da282c48e0f959a56",
      "542e865145b547ffbe61dec7fb94bab7",
      "1ac6bf7c4d7d4fbd8d1c85ec426854db",
      "808d2ba240c241e9a6989a03c4134a33",
      "886551311e7d4ee9823ecd34dfc82811",
      "988ec5ae620d4d67b6749ee92a2cb560",
      "9463e5ed29e74f05869715f4669d1fa5",
      "5e57195d10d7414c9f418af4e7eca84a",
      "e4bb3941e21d45f2b2327690b4d589bf",
      "321f61ce086b4ace9260a2d55afbdefa",
      "94f8b1fb0c764cfa9af078bd238623d4",
      "621130d9d8cf468abe5709a85f07d106",
      "1453b743641b45758303e91bfedafe03",
      "a7aeaf582d15403dbe447d57789b691f",
      "d1d0b028b6c04d59ada3bdfb7efde504",
      "0a203635e4a54efd96b85633164a067d",
      "c55350fd925a454eae62f9da4ed21962",
      "21dd3d5e1468453ab2f81d5e184a990e",
      "a18149514fe94397abd4bcafd4df0807",
      "c73b50f20f5f4b6c8ccca8e1ec61e738",
      "fb17189f06074ca39d8251ea2ece15f3",
      "b379be7248c84e88b3a5bc8362e56e2f",
      "7e85b97fbf8642ecb7613a8b3646b6dc",
      "f13fd92805504c0dae5b22e404c256fa",
      "86c67fc1ac0d47bbace0fe3b6f24c7ce",
      "46568a6cac834c86854b6e41c7e7219a",
      "fd38ef9382a6488a8be23d5bdb1fb533",
      "e01ecdf66c3143809825cbbad4aaeebb"
     ]
    },
    "id": "r3i4rnIhapWe",
    "outputId": "804a7c34-2089-4dab-b736-e2f92ba30f94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.common.params:error loading _jsonnet (this is expected on Windows), treating C:\\Users\\arsya\\AppData\\Local\\Temp\\tmpgqizmf6o\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x0000016D8D2CC4C8>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e956d66da6b048dbb04bee6a6bd7b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Data\nsentences -> 0\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15676\\4271695536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpanModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15676\\4271695536.py\u001b[0m in \u001b[0;36mpredict_sentence\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSplitEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_to_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_full_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\aste\\wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, path_in, path_out)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mnum_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mnum_gold\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\.venv\\lib\\site-packages\\pydantic\\main.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Data\nsentences -> 0\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "# Use pretrained SpanModel weights for prediction\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "from wrapper import SpanModel\n",
    "\n",
    "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
    "    path_in = \"temp_in.txt\"\n",
    "    path_out = \"temp_out.txt\"\n",
    "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
    "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
    "    data.save_to_path(path_in)\n",
    "    model.predict(path_in, path_out)\n",
    "    data = Data.load_from_full_path(path_out)\n",
    "    return data.sentences[0]\n",
    "\n",
    "text = \"buset nih busway arah ke blok M lama bener datengnya\"\n",
    "\n",
    "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
    "sent = predict_sentence(text, model)\n",
    "\n",
    "for t in sent.triples:\n",
    "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
    "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
    "    print()\n",
    "    print(dict(target=target, opinion=opinion, sentiment=t.label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell is for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "srSNwqUz-39x",
    "outputId": "9a34cc00-477f-4002-c8ec-e357284c2bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights_dir': WindowsPath('outputs/TJ - Overall Dataset/seed_4/weights')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating training_config/config.jsonnet as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating snippet as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:05,908 - INFO - allennlp.common.params - random_seed = 4\n",
      "2025-05-05 16:54:05,908 - INFO - allennlp.common.params - numpy_seed = 4\n",
      "2025-05-05 16:54:05,908 - INFO - allennlp.common.params - pytorch_seed = 4\n",
      "2025-05-05 16:54:05,983 - INFO - allennlp.common.checks - Pytorch version: 1.7.1+cu101\n",
      "2025-05-05 16:54:05,983 - INFO - allennlp.common.params - type = default\n",
      "2025-05-05 16:54:05,983 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2025-05-05 16:54:05,983 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2025-05-05 16:54:05,991 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2025-05-05 16:54:05,991 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2025-05-05 16:54:05,991 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2025-05-05 16:54:05,991 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2025-05-05 16:54:06,002 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2025-05-05 16:54:06,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2025-05-05 16:54:06,005 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2025-05-05 16:54:06,008 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = indobenchmark/indobert-base-p1\n",
      "2025-05-05 16:54:06,010 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2025-05-05 16:54:06,014 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2025-05-05 16:54:06,015 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "################################################################################\n",
      "2025-05-05 16:54:11,217 - INFO - allennlp.common.params - train_data_path = D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\train.json\n",
      "2025-05-05 16:54:11,224 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x000002F66AFECF48>\n",
      "2025-05-05 16:54:11,224 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2025-05-05 16:54:11,224 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2025-05-05 16:54:11,224 - INFO - allennlp.common.params - validation_data_path = D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\dev.json\n",
      "2025-05-05 16:54:11,232 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2025-05-05 16:54:11,237 - INFO - allennlp.common.params - test_data_path = D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\dev.json\n",
      "2025-05-05 16:54:11,239 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2025-05-05 16:54:11,243 - INFO - allennlp.common.params - batch_weight_key = \n",
      "2025-05-05 16:54:11,244 - INFO - allennlp.training.util - Reading training data from D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d033a3250ca4706974d425b68663024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:14,232 - INFO - allennlp.training.util - Reading validation data from D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\dev.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c33ceb91ce24ef9aadd8abf6bafabda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:15,148 - INFO - allennlp.training.util - Reading test data from D:\\KULIAH\\Semester 6\\MBKM\\Bangkit2024\\Entrepeneur Track\\Unsmoke\\Machine Learning\\TA\\Span-ASTE\\outputs\\TJ - Overall Dataset\\seed_4\\temp_data\\dev.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3b4fe80a9142a391812f9663aed027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:15,639 - INFO - allennlp.common.params - type = from_instances\n",
      "2025-05-05 16:54:15,643 - INFO - allennlp.common.params - min_count = None\n",
      "2025-05-05 16:54:15,643 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2025-05-05 16:54:15,645 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2025-05-05 16:54:15,645 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2025-05-05 16:54:15,649 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2025-05-05 16:54:15,649 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2025-05-05 16:54:15,649 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2025-05-05 16:54:15,649 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2025-05-05 16:54:15,659 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2025-05-05 16:54:15,661 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1720083b5f46868b3dc8ed73c756ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:15,998 - INFO - allennlp.common.params - model.type = span_model\n",
      "2025-05-05 16:54:15,998 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2025-05-05 16:54:15,998 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2025-05-05 16:54:15,998 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2025-05-05 16:54:16,008 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = indobenchmark/indobert-base-p1\n",
      "2025-05-05 16:54:16,008 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2025-05-05 16:54:16,008 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2025-05-05 16:54:16,008 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2025-05-05 16:54:16,017 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2025-05-05 16:54:16,019 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2025-05-05 16:54:16,020 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2025-05-05 16:54:19,939 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2025-05-05 16:54:19,939 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2025-05-05 16:54:19,939 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2025-05-05 16:54:19,939 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2025-05-05 16:54:19,947 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2025-05-05 16:54:19,947 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2025-05-05 16:54:19,947 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
      "2025-05-05 16:54:19,947 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
      "2025-05-05 16:54:19,955 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
      "2025-05-05 16:54:19,959 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2025-05-05 16:54:19,961 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2025-05-05 16:54:19,963 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2025-05-05 16:54:19,966 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2025-05-05 16:54:19,968 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2025-05-05 16:54:19,968 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2025-05-05 16:54:19,973 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2025-05-05 16:54:19,975 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "2025-05-05 16:54:19,985 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2025-05-05 16:54:19,987 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "2025-05-05 16:54:19,999 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2025-05-05 16:54:20,002 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2025-05-05 16:54:20,002 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2025-05-05 16:54:20,007 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2025-05-05 16:54:20,009 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2025-05-05 16:54:20,010 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x000002F69C260798>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "2025-05-05 16:54:20,034 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2025-05-05 16:54:20,039 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,044 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,048 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,083 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2025-05-05 16:54:20,083 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2025-05-05 16:54:20,089 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2025-05-05 16:54:20,089 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2025-05-05 16:54:20,089 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2025-05-05 16:54:20,127 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2025-05-05 16:54:20,130 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,130 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,139 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,139 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2025-05-05 16:54:20,147 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2025-05-05 16:54:20,147 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2025-05-05 16:54:20,147 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2025-05-05 16:54:20,147 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2025-05-05 16:54:20,156 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2025-05-05 16:54:20,156 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2025-05-05 16:54:20,164 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
      "2025-05-05 16:54:20,173 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2025-05-05 16:54:20,177 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2025-05-05 16:54:20,178 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2025-05-05 16:54:20,178 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2025-05-05 16:54:20,184 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2025-05-05 16:54:20,184 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2025-05-05 16:54:20,184 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,191 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,191 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,191 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,198 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2025-05-05 16:54:20,200 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2025-05-05 16:54:20,202 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2025-05-05 16:54:20,204 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2025-05-05 16:54:20,207 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2025-05-05 16:54:20,210 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2025-05-05 16:54:20,212 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,215 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,216 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,219 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,219 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2025-05-05 16:54:20,224 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2025-05-05 16:54:20,225 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,225 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,225 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,232 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,234 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2025-05-05 16:54:20,236 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2025-05-05 16:54:20,240 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2025-05-05 16:54:20,242 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2025-05-05 16:54:20,244 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2025-05-05 16:54:20,247 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2025-05-05 16:54:20,247 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,247 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,247 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,257 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,259 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2025-05-05 16:54:20,259 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2025-05-05 16:54:20,264 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,266 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,267 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,267 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,267 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2025-05-05 16:54:20,274 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2025-05-05 16:54:20,275 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2025-05-05 16:54:20,277 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2025-05-05 16:54:20,282 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2025-05-05 16:54:20,285 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2025-05-05 16:54:20,286 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,289 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,292 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,293 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,293 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2025-05-05 16:54:20,299 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2025-05-05 16:54:20,300 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,300 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2025-05-05 16:54:20,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2025-05-05 16:54:20,315 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2025-05-05 16:54:20,317 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2025-05-05 16:54:20,318 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2025-05-05 16:54:20,320 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2025-05-05 16:54:20,324 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,326 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,327 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,328 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,331 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2025-05-05 16:54:20,334 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2025-05-05 16:54:20,335 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,335 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,340 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,342 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,342 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2025-05-05 16:54:20,347 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2025-05-05 16:54:20,349 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2025-05-05 16:54:20,351 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2025-05-05 16:54:20,352 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2025-05-05 16:54:20,356 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2025-05-05 16:54:20,358 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,359 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,359 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,365 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,367 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2025-05-05 16:54:20,367 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2025-05-05 16:54:20,373 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,375 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,376 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,378 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,382 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2025-05-05 16:54:20,383 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2025-05-05 16:54:20,385 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2025-05-05 16:54:20,385 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2025-05-05 16:54:20,391 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2025-05-05 16:54:20,392 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2025-05-05 16:54:20,394 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,394 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,400 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,402 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,402 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2025-05-05 16:54:20,402 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2025-05-05 16:54:20,409 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,410 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,412 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,414 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,416 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2025-05-05 16:54:20,416 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2025-05-05 16:54:20,416 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2025-05-05 16:54:20,423 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2025-05-05 16:54:20,425 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2025-05-05 16:54:20,447 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2025-05-05 16:54:20,450 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,452 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,467 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,470 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2025-05-05 16:54:20,472 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2025-05-05 16:54:20,487 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,497 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,497 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,505 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,505 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2025-05-05 16:54:20,515 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2025-05-05 16:54:20,518 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2025-05-05 16:54:20,521 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2025-05-05 16:54:20,523 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2025-05-05 16:54:20,523 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2025-05-05 16:54:20,530 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,533 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,535 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,536 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,539 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2025-05-05 16:54:20,541 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2025-05-05 16:54:20,543 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,543 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,549 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,551 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,553 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2025-05-05 16:54:20,554 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2025-05-05 16:54:20,555 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2025-05-05 16:54:20,555 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2025-05-05 16:54:20,555 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2025-05-05 16:54:20,555 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2025-05-05 16:54:20,563 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,563 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,563 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,563 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,580 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2025-05-05 16:54:20,584 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2025-05-05 16:54:20,587 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,593 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,595 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,597 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,597 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2025-05-05 16:54:20,597 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2025-05-05 16:54:20,605 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2025-05-05 16:54:20,605 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2025-05-05 16:54:20,613 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2025-05-05 16:54:20,617 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2025-05-05 16:54:20,622 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,622 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,622 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,630 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,630 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2025-05-05 16:54:20,630 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2025-05-05 16:54:20,639 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,643 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,648 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,651 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,656 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2025-05-05 16:54:20,659 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2025-05-05 16:54:20,662 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2025-05-05 16:54:20,668 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2025-05-05 16:54:20,673 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2025-05-05 16:54:20,676 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2025-05-05 16:54:20,679 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,681 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,682 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,682 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,690 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2025-05-05 16:54:20,691 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2025-05-05 16:54:20,693 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,705 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,714 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2025-05-05 16:54:20,718 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2025-05-05 16:54:20,721 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2025-05-05 16:54:20,723 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2025-05-05 16:54:20,724 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2025-05-05 16:54:20,726 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2025-05-05 16:54:20,727 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2025-05-05 16:54:20,731 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2025-05-05 16:54:20,731 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2025-05-05 16:54:20,731 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2025-05-05 16:54:20,739 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2025-05-05 16:54:20,742 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2025-05-05 16:54:20,743 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2025-05-05 16:54:20,748 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2025-05-05 16:54:20,751 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2025-05-05 16:54:20,752 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2025-05-05 16:54:20,755 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2025-05-05 16:54:20,759 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2025-05-05 16:54:20,761 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2025-05-05 16:54:20,768 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2025-05-05 16:54:20,772 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2025-05-05 16:54:20,776 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2025-05-05 16:54:20,779 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2025-05-05 16:54:20,783 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2025-05-05 16:54:20,785 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2025-05-05 16:54:20,787 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2025-05-05 16:54:20,790 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2025-05-05 16:54:20,792 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2025-05-05 16:54:20,794 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
      "2025-05-05 16:54:20,799 - INFO - filelock - Lock 3257391799240 acquired on outputs\\TJ - Overall Dataset\\seed_4\\weights\\vocabulary\\.lock\n",
      "2025-05-05 16:54:20,807 - INFO - filelock - Lock 3257391799240 released on outputs\\TJ - Overall Dataset\\seed_4\\weights\\vocabulary\\.lock\n",
      "2025-05-05 16:54:20,810 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2025-05-05 16:54:20,811 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2025-05-05 16:54:20,815 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2025-05-05 16:54:20,817 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2025-05-05 16:54:20,819 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2025-05-05 16:54:20,823 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2025-05-05 16:54:20,826 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2025-05-05 16:54:20,828 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2025-05-05 16:54:20,832 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2025-05-05 16:54:20,835 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2025-05-05 16:54:20,836 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2025-05-05 16:54:20,839 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2025-05-05 16:54:20,841 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2025-05-05 16:54:20,841 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2025-05-05 16:54:20,847 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2025-05-05 16:54:20,850 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2025-05-05 16:54:20,852 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2025-05-05 16:54:20,852 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2025-05-05 16:54:20,857 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2025-05-05 16:54:20,859 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2025-05-05 16:54:20,859 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2025-05-05 16:54:20,859 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2025-05-05 16:54:20,866 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2025-05-05 16:54:20,868 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2025-05-05 16:54:20,868 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2025-05-05 16:54:20,872 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2025-05-05 16:54:20,875 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2025-05-05 16:54:20,876 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2025-05-05 16:54:20,879 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2025-05-05 16:54:20,882 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2025-05-05 16:54:20,882 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2025-05-05 16:54:20,882 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2025-05-05 16:54:20,890 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2025-05-05 16:54:20,892 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2025-05-05 16:54:20,894 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2025-05-05 16:54:20,894 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2025-05-05 16:54:20,898 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2025-05-05 16:54:20,899 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2025-05-05 16:54:20,902 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2025-05-05 16:54:20,903 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2025-05-05 16:54:20,906 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2025-05-05 16:54:20,909 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2025-05-05 16:54:20,909 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2025-05-05 16:54:20,914 - INFO - allennlp.common.params - trainer.patience = 3\n",
      "2025-05-05 16:54:20,916 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
      "2025-05-05 16:54:20,919 - INFO - allennlp.common.params - trainer.num_epochs = 30\n",
      "2025-05-05 16:54:20,919 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
      "2025-05-05 16:54:20,923 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
      "2025-05-05 16:54:20,925 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2025-05-05 16:54:20,927 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2025-05-05 16:54:20,929 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2025-05-05 16:54:20,931 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2025-05-05 16:54:20,933 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2025-05-05 16:54:20,935 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2025-05-05 16:54:20,937 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2025-05-05 16:54:20,938 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x000002F66AFC4588>\n",
      "2025-05-05 16:54:20,938 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2025-05-05 16:54:20,938 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
      "2025-05-05 16:54:20,947 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
      "2025-05-05 16:54:20,950 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
      "2025-05-05 16:54:20,951 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
      "2025-05-05 16:54:23,255 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
      "2025-05-05 16:54:23,263 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
      "2025-05-05 16:54:23,263 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2025-05-05 16:54:23,263 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2025-05-05 16:54:23,271 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
      "2025-05-05 16:54:23,271 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
      "2025-05-05 16:54:23,271 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2025-05-05 16:54:23,280 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
      "2025-05-05 16:54:23,283 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
      "2025-05-05 16:54:23,283 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_relation._relation_scorers.None__relation_labels.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_scorers.None__relation_labels.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_relation.d_embedder.embedder.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_ner._ner_scorers.None__ner_labels.1._module.weight'], {}\n",
      "2025-05-05 16:54:23,291 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
      "2025-05-05 16:54:23,293 - INFO - allennlp.training.optimizers - Number of trainable parameters: 125208841\n",
      "2025-05-05 16:54:23,298 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2025-05-05 16:54:23,303 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2025-05-05 16:54:23,306 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2025-05-05 16:54:23,308 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2025-05-05 16:54:23,310 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2025-05-05 16:54:23,314 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2025-05-05 16:54:23,317 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2025-05-05 16:54:23,319 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2025-05-05 16:54:23,322 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2025-05-05 16:54:23,325 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2025-05-05 16:54:23,326 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2025-05-05 16:54:23,327 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2025-05-05 16:54:23,331 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2025-05-05 16:54:23,332 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2025-05-05 16:54:23,332 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,339 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,341 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,343 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,343 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,349 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,351 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2025-05-05 16:54:23,352 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2025-05-05 16:54:23,352 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,357 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,358 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2025-05-05 16:54:23,360 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2025-05-05 16:54:23,363 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2025-05-05 16:54:23,365 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2025-05-05 16:54:23,367 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2025-05-05 16:54:23,368 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2025-05-05 16:54:23,372 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,375 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,376 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,386 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,388 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,388 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,396 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2025-05-05 16:54:23,396 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2025-05-05 16:54:23,408 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,410 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,414 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2025-05-05 16:54:23,417 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2025-05-05 16:54:23,419 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2025-05-05 16:54:23,423 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2025-05-05 16:54:23,425 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2025-05-05 16:54:23,427 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2025-05-05 16:54:23,430 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,432 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,433 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,442 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,444 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,448 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2025-05-05 16:54:23,451 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2025-05-05 16:54:23,453 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2025-05-05 16:54:23,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2025-05-05 16:54:23,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2025-05-05 16:54:23,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2025-05-05 16:54:23,469 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2025-05-05 16:54:23,473 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2025-05-05 16:54:23,477 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,480 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,480 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,480 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,488 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,491 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,494 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2025-05-05 16:54:23,498 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2025-05-05 16:54:23,500 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,506 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,508 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2025-05-05 16:54:23,510 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2025-05-05 16:54:23,511 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2025-05-05 16:54:23,514 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2025-05-05 16:54:23,516 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2025-05-05 16:54:23,517 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2025-05-05 16:54:23,518 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,520 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,521 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,523 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,524 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,525 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,526 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2025-05-05 16:54:23,528 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2025-05-05 16:54:23,531 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,532 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,533 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2025-05-05 16:54:23,535 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2025-05-05 16:54:23,538 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2025-05-05 16:54:23,540 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2025-05-05 16:54:23,542 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2025-05-05 16:54:23,543 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2025-05-05 16:54:23,545 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,547 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,548 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,550 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,551 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,555 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2025-05-05 16:54:23,557 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2025-05-05 16:54:23,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,585 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,593 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2025-05-05 16:54:23,599 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2025-05-05 16:54:23,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2025-05-05 16:54:23,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2025-05-05 16:54:23,610 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2025-05-05 16:54:23,615 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2025-05-05 16:54:23,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,625 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,628 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,632 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,635 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,639 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2025-05-05 16:54:23,642 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2025-05-05 16:54:23,644 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,650 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,652 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2025-05-05 16:54:23,658 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2025-05-05 16:54:23,660 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2025-05-05 16:54:23,665 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2025-05-05 16:54:23,667 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2025-05-05 16:54:23,669 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2025-05-05 16:54:23,673 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,677 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,682 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,684 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,693 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,695 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,699 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2025-05-05 16:54:23,701 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2025-05-05 16:54:23,704 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,707 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,710 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2025-05-05 16:54:23,714 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2025-05-05 16:54:23,719 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2025-05-05 16:54:23,725 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2025-05-05 16:54:23,728 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2025-05-05 16:54:23,730 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2025-05-05 16:54:23,730 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,730 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,738 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,748 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,752 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,757 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,760 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2025-05-05 16:54:23,762 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2025-05-05 16:54:23,767 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,769 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,771 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2025-05-05 16:54:23,774 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2025-05-05 16:54:23,776 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2025-05-05 16:54:23,778 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2025-05-05 16:54:23,782 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2025-05-05 16:54:23,782 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2025-05-05 16:54:23,782 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,782 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,791 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,793 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,794 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,797 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,800 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2025-05-05 16:54:23,802 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2025-05-05 16:54:23,802 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,807 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,810 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2025-05-05 16:54:23,811 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2025-05-05 16:54:23,816 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2025-05-05 16:54:23,818 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2025-05-05 16:54:23,819 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2025-05-05 16:54:23,821 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2025-05-05 16:54:23,825 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,826 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,828 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,830 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,832 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,834 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,836 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2025-05-05 16:54:23,839 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2025-05-05 16:54:23,842 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,843 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,847 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2025-05-05 16:54:23,850 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2025-05-05 16:54:23,851 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2025-05-05 16:54:23,853 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2025-05-05 16:54:23,856 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2025-05-05 16:54:23,858 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2025-05-05 16:54:23,858 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2025-05-05 16:54:23,862 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2025-05-05 16:54:23,865 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,867 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,869 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2025-05-05 16:54:23,873 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2025-05-05 16:54:23,875 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2025-05-05 16:54:23,876 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2025-05-05 16:54:23,878 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2025-05-05 16:54:23,880 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2025-05-05 16:54:23,882 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2025-05-05 16:54:23,885 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2025-05-05 16:54:23,888 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2025-05-05 16:54:23,891 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2025-05-05 16:54:23,931 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2025-05-05 16:54:23,940 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2025-05-05 16:54:23,942 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2025-05-05 16:54:23,944 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2025-05-05 16:54:23,949 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
      "2025-05-05 16:54:23,952 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2025-05-05 16:54:23,955 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2025-05-05 16:54:23,955 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2025-05-05 16:54:23,955 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2025-05-05 16:54:23,988 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
      "2025-05-05 16:54:23,990 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
      "2025-05-05 16:54:23,997 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2025-05-05 16:54:24,001 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
      "2025-05-05 16:54:24,004 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2025-05-05 16:54:24,005 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2025-05-05 16:54:24,005 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2025-05-05 16:54:24,005 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2025-05-05 16:54:24,013 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2025-05-05 16:54:24,013 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
      "2025-05-05 16:54:24,018 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2025-05-05 16:54:24,018 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
      "2025-05-05 16:54:24,018 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
      "2025-05-05 16:54:24,022 - INFO - allennlp.common.params - summary_interval = 100\n",
      "2025-05-05 16:54:24,034 - INFO - allennlp.common.params - histogram_interval = None\n",
      "2025-05-05 16:54:24,040 - INFO - allennlp.common.params - batch_size_interval = None\n",
      "2025-05-05 16:54:24,040 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
      "2025-05-05 16:54:24,047 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
      "2025-05-05 16:54:24,053 - INFO - allennlp.common.params - get_batch_num_total = None\n",
      "2025-05-05 16:54:24,138 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2025-05-05 16:54:24,146 - INFO - allennlp.training.trainer - Epoch 0/29\n",
      "2025-05-05 16:54:24,146 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 16:54:24,146 - INFO - allennlp.training.trainer - GPU 0 memory usage: 478M\n",
      "2025-05-05 16:54:24,155 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5106b9d36a7f4d4e99f66e23c829d96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:54:24,880 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n",
      "2025-05-05 17:04:22,936 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f31f96a12a4e1597a50d076c0bd7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:04:46,390 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:04:46,402 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,406 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,410 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,415 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.178  |     0.518\n",
      "2025-05-05 17:04:46,418 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.231  |     0.625\n",
      "2025-05-05 17:04:46,422 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.145  |     0.442\n",
      "2025-05-05 17:04:46,427 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.178  |     0.518\n",
      "2025-05-05 17:04:46,429 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.231  |     0.625\n",
      "2025-05-05 17:04:46,433 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.145  |     0.442\n",
      "2025-05-05 17:04:46,436 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,440 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,444 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.002  |     0.000\n",
      "2025-05-05 17:04:46,447 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   477.803  |       N/A\n",
      "2025-05-05 17:04:46,453 - INFO - allennlp.training.tensorboard_writer - loss                      |    21.387  |    12.890\n",
      "2025-05-05 17:04:46,460 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:04:54,647 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 17:05:00,743 - INFO - allennlp.training.trainer - Epoch duration: 0:10:36.596458\n",
      "2025-05-05 17:05:00,744 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:07:41\n",
      "2025-05-05 17:05:00,746 - INFO - allennlp.training.trainer - Epoch 1/29\n",
      "2025-05-05 17:05:00,746 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:05:00,746 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:05:00,755 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1536f8281b4315b97ae92de0c3a94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:14:55,777 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0456741de9434db1f35438d126f48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:15:16,854 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:15:16,858 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.044  |     0.000\n",
      "2025-05-05 17:15:16,861 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.262  |     0.000\n",
      "2025-05-05 17:15:16,866 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.024  |     0.000\n",
      "2025-05-05 17:15:16,869 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.544  |     0.571\n",
      "2025-05-05 17:15:16,872 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.659  |     0.710\n",
      "2025-05-05 17:15:16,877 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.463  |     0.478\n",
      "2025-05-05 17:15:16,881 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.544  |     0.571\n",
      "2025-05-05 17:15:16,884 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.659  |     0.710\n",
      "2025-05-05 17:15:16,887 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.463  |     0.478\n",
      "2025-05-05 17:15:16,891 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.044  |     0.000\n",
      "2025-05-05 17:15:16,894 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.262  |     0.000\n",
      "2025-05-05 17:15:16,898 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.024  |     0.000\n",
      "2025-05-05 17:15:16,902 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 17:15:16,906 - INFO - allennlp.training.tensorboard_writer - loss                      |    13.067  |    12.482\n",
      "2025-05-05 17:15:16,909 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:15:26,361 - INFO - allennlp.training.trainer - Epoch duration: 0:10:25.615117\n",
      "2025-05-05 17:15:26,363 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:54:31\n",
      "2025-05-05 17:15:26,364 - INFO - allennlp.training.trainer - Epoch 2/29\n",
      "2025-05-05 17:15:26,366 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:15:26,368 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:15:26,371 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e0b3ed03564c08b635dda1757743bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:25:06,818 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eb288a4bf24a6abeae70416353a567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:25:28,665 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:25:28,669 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.205  |     0.169\n",
      "2025-05-05 17:25:28,673 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.385  |     0.663\n",
      "2025-05-05 17:25:28,677 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.139  |     0.097\n",
      "2025-05-05 17:25:28,681 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.628  |     0.550\n",
      "2025-05-05 17:25:28,683 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.705  |     0.711\n",
      "2025-05-05 17:25:28,685 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.566  |     0.449\n",
      "2025-05-05 17:25:28,688 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.628  |     0.550\n",
      "2025-05-05 17:25:28,691 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.705  |     0.711\n",
      "2025-05-05 17:25:28,694 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.566  |     0.449\n",
      "2025-05-05 17:25:28,698 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.205  |     0.169\n",
      "2025-05-05 17:25:28,702 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.385  |     0.663\n",
      "2025-05-05 17:25:28,706 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.139  |     0.097\n",
      "2025-05-05 17:25:28,709 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 17:25:28,713 - INFO - allennlp.training.tensorboard_writer - loss                      |    11.974  |    16.550\n",
      "2025-05-05 17:25:28,716 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:25:36,467 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 17:25:45,119 - INFO - allennlp.training.trainer - Epoch duration: 0:10:18.753584\n",
      "2025-05-05 17:25:45,121 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:42:08\n",
      "2025-05-05 17:25:45,123 - INFO - allennlp.training.trainer - Epoch 3/29\n",
      "2025-05-05 17:25:45,125 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:25:45,127 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:25:45,130 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f42ded56034e31ad1457f08218f800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:35:27,645 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122d5b0bfe3848f0971e6ba3275abeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:35:49,204 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:35:49,206 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.294  |     0.221\n",
      "2025-05-05 17:35:49,212 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.402  |     0.541\n",
      "2025-05-05 17:35:49,215 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.232  |     0.139\n",
      "2025-05-05 17:35:49,218 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.671  |     0.570\n",
      "2025-05-05 17:35:49,222 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.731  |     0.627\n",
      "2025-05-05 17:35:49,225 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.620  |     0.522\n",
      "2025-05-05 17:35:49,228 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.671  |     0.570\n",
      "2025-05-05 17:35:49,234 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.731  |     0.627\n",
      "2025-05-05 17:35:49,237 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.620  |     0.522\n",
      "2025-05-05 17:35:49,241 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.294  |     0.221\n",
      "2025-05-05 17:35:49,244 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.402  |     0.541\n",
      "2025-05-05 17:35:49,248 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.232  |     0.139\n",
      "2025-05-05 17:35:49,251 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 17:35:49,254 - INFO - allennlp.training.tensorboard_writer - loss                      |    12.132  |    14.551\n",
      "2025-05-05 17:35:49,256 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:35:56,486 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 17:36:03,368 - INFO - allennlp.training.trainer - Epoch duration: 0:10:18.244903\n",
      "2025-05-05 17:36:03,370 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:30:44\n",
      "2025-05-05 17:36:03,372 - INFO - allennlp.training.trainer - Epoch 4/29\n",
      "2025-05-05 17:36:03,373 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:36:03,376 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:36:03,380 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfdacdbb6ce4bbd89451449662211b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:46:19,728 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f17c9e722747318663cbf4337e9981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:46:43,838 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:46:43,849 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.397  |     0.342\n",
      "2025-05-05 17:46:43,854 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.496  |     0.580\n",
      "2025-05-05 17:46:43,858 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.331  |     0.243\n",
      "2025-05-05 17:46:43,861 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.722  |     0.598\n",
      "2025-05-05 17:46:43,863 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.777  |     0.664\n",
      "2025-05-05 17:46:43,873 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.675  |     0.543\n",
      "2025-05-05 17:46:43,876 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.722  |     0.598\n",
      "2025-05-05 17:46:43,880 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.777  |     0.664\n",
      "2025-05-05 17:46:43,883 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.675  |     0.543\n",
      "2025-05-05 17:46:43,885 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.397  |     0.342\n",
      "2025-05-05 17:46:43,891 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.496  |     0.580\n",
      "2025-05-05 17:46:43,894 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.331  |     0.243\n",
      "2025-05-05 17:46:43,899 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 17:46:43,905 - INFO - allennlp.training.tensorboard_writer - loss                      |    11.510  |    15.595\n",
      "2025-05-05 17:46:43,910 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:46:52,385 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 17:46:57,602 - INFO - allennlp.training.trainer - Epoch duration: 0:10:54.229947\n",
      "2025-05-05 17:46:57,602 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:22:47\n",
      "2025-05-05 17:46:57,602 - INFO - allennlp.training.trainer - Epoch 5/29\n",
      "2025-05-05 17:46:57,610 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:46:57,610 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:46:57,619 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b540f567b27415ea89076c0480d2574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:57:04,673 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a519f3905b434249b789589bf01f9e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:57:27,450 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 17:57:27,455 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.467  |     0.352\n",
      "2025-05-05 17:57:27,458 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.539  |     0.479\n",
      "2025-05-05 17:57:27,464 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.412  |     0.278\n",
      "2025-05-05 17:57:27,464 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.762  |     0.608\n",
      "2025-05-05 17:57:27,471 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.806  |     0.693\n",
      "2025-05-05 17:57:27,478 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.723  |     0.542\n",
      "2025-05-05 17:57:27,481 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.762  |     0.608\n",
      "2025-05-05 17:57:27,484 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.806  |     0.693\n",
      "2025-05-05 17:57:27,487 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.723  |     0.542\n",
      "2025-05-05 17:57:27,489 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.467  |     0.352\n",
      "2025-05-05 17:57:27,493 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.539  |     0.479\n",
      "2025-05-05 17:57:27,495 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.412  |     0.278\n",
      "2025-05-05 17:57:27,498 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 17:57:27,504 - INFO - allennlp.training.tensorboard_writer - loss                      |    10.743  |    14.843\n",
      "2025-05-05 17:57:27,510 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 17:57:35,111 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 17:57:40,696 - INFO - allennlp.training.trainer - Epoch duration: 0:10:43.094541\n",
      "2025-05-05 17:57:40,697 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:13:06\n",
      "2025-05-05 17:57:40,697 - INFO - allennlp.training.trainer - Epoch 6/29\n",
      "2025-05-05 17:57:40,697 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 17:57:40,705 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 17:57:40,705 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a22f6b00a3345be9d81b2cbc1fb2981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:07:47,705 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d2d84c1e604ce0af311c724e5529ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:08:12,690 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 18:08:12,697 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.481  |     0.335\n",
      "2025-05-05 18:08:12,701 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.555  |     0.378\n",
      "2025-05-05 18:08:12,701 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.424  |     0.301\n",
      "2025-05-05 18:08:12,709 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.782  |     0.589\n",
      "2025-05-05 18:08:12,710 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.823  |     0.547\n",
      "2025-05-05 18:08:12,717 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.745  |     0.638\n",
      "2025-05-05 18:08:12,720 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.782  |     0.589\n",
      "2025-05-05 18:08:12,725 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.823  |     0.547\n",
      "2025-05-05 18:08:12,729 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.745  |     0.638\n",
      "2025-05-05 18:08:12,734 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.481  |     0.335\n",
      "2025-05-05 18:08:12,737 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.555  |     0.378\n",
      "2025-05-05 18:08:12,741 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.424  |     0.301\n",
      "2025-05-05 18:08:12,744 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 18:08:12,747 - INFO - allennlp.training.tensorboard_writer - loss                      |    10.193  |    17.133\n",
      "2025-05-05 18:08:12,753 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 18:08:20,504 - INFO - allennlp.training.trainer - Epoch duration: 0:10:39.807482\n",
      "2025-05-05 18:08:20,504 - INFO - allennlp.training.trainer - Estimated training time remaining: 4:02:56\n",
      "2025-05-05 18:08:20,504 - INFO - allennlp.training.trainer - Epoch 7/29\n",
      "2025-05-05 18:08:20,513 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 18:08:20,513 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 18:08:20,513 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caec5551aaca440bb871f79922fabdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:18:27,085 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fecdb841b84a9f8b400996448bb252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:18:51,179 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 18:18:51,182 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.558  |     0.364\n",
      "2025-05-05 18:18:51,187 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.625  |     0.479\n",
      "2025-05-05 18:18:51,191 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.504  |     0.294\n",
      "2025-05-05 18:18:51,192 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.818  |     0.591\n",
      "2025-05-05 18:18:51,199 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.853  |     0.597\n",
      "2025-05-05 18:18:51,204 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.787  |     0.584\n",
      "2025-05-05 18:18:51,208 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.818  |     0.591\n",
      "2025-05-05 18:18:51,212 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.853  |     0.597\n",
      "2025-05-05 18:18:51,215 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.787  |     0.584\n",
      "2025-05-05 18:18:51,218 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.558  |     0.364\n",
      "2025-05-05 18:18:51,222 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.625  |     0.479\n",
      "2025-05-05 18:18:51,225 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.504  |     0.294\n",
      "2025-05-05 18:18:51,227 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 18:18:51,231 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.520  |    28.831\n",
      "2025-05-05 18:18:51,236 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 18:18:58,504 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 18:19:05,106 - INFO - allennlp.training.trainer - Epoch duration: 0:10:44.601798\n",
      "2025-05-05 18:19:05,109 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:52:52\n",
      "2025-05-05 18:19:05,109 - INFO - allennlp.training.trainer - Epoch 8/29\n",
      "2025-05-05 18:19:05,109 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 18:19:05,116 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 18:19:05,120 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a162811a2659470798328d5ca321c09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:29:05,579 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aea8bbe4ba462b9d01c8389ea433db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:29:29,381 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 18:29:29,386 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.614  |     0.376\n",
      "2025-05-05 18:29:29,390 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.676  |     0.490\n",
      "2025-05-05 18:29:29,390 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.562  |     0.305\n",
      "2025-05-05 18:29:29,399 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.849  |     0.600\n",
      "2025-05-05 18:29:29,403 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.879  |     0.652\n",
      "2025-05-05 18:29:29,408 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.820  |     0.556\n",
      "2025-05-05 18:29:29,412 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.849  |     0.600\n",
      "2025-05-05 18:29:29,418 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.879  |     0.652\n",
      "2025-05-05 18:29:29,421 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.820  |     0.556\n",
      "2025-05-05 18:29:29,426 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.614  |     0.376\n",
      "2025-05-05 18:29:29,429 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.676  |     0.490\n",
      "2025-05-05 18:29:29,433 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.562  |     0.305\n",
      "2025-05-05 18:29:29,435 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 18:29:29,440 - INFO - allennlp.training.tensorboard_writer - loss                      |     8.746  |    23.003\n",
      "2025-05-05 18:29:29,444 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 18:29:36,016 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 18:29:45,289 - INFO - allennlp.training.trainer - Epoch duration: 0:10:40.180020\n",
      "2025-05-05 18:29:45,290 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:42:29\n",
      "2025-05-05 18:29:45,292 - INFO - allennlp.training.trainer - Epoch 9/29\n",
      "2025-05-05 18:29:45,295 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 18:29:45,297 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 18:29:45,299 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1eacb7b73543e3a8fa6e11174d34e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:39:48,863 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c17ed883ffd485f82a7594900c197af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:40:11,970 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 18:40:11,976 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.644  |     0.405\n",
      "2025-05-05 18:40:11,981 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.713  |     0.531\n",
      "2025-05-05 18:40:11,981 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.586  |     0.327\n",
      "2025-05-05 18:40:11,988 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.853  |     0.582\n",
      "2025-05-05 18:40:11,991 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.886  |     0.730\n",
      "2025-05-05 18:40:11,997 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.822  |     0.484\n",
      "2025-05-05 18:40:12,001 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.853  |     0.582\n",
      "2025-05-05 18:40:12,005 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.886  |     0.730\n",
      "2025-05-05 18:40:12,007 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.822  |     0.484\n",
      "2025-05-05 18:40:12,010 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.644  |     0.405\n",
      "2025-05-05 18:40:12,014 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.713  |     0.531\n",
      "2025-05-05 18:40:12,017 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.586  |     0.327\n",
      "2025-05-05 18:40:12,019 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 18:40:12,024 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.867  |    31.038\n",
      "2025-05-05 18:40:12,025 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 18:40:19,798 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 18:40:25,167 - INFO - allennlp.training.trainer - Epoch duration: 0:10:39.875366\n",
      "2025-05-05 18:40:25,167 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:32:02\n",
      "2025-05-05 18:40:25,167 - INFO - allennlp.training.trainer - Epoch 10/29\n",
      "2025-05-05 18:40:25,167 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 18:40:25,176 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 18:40:25,179 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1a1a3480254dd982e0eb39bf42d77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:50:04,233 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c89196f0394050bdc25d9a3a93b349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:50:24,944 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 18:50:24,947 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.680  |     0.381\n",
      "2025-05-05 18:50:24,950 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.725  |     0.433\n",
      "2025-05-05 18:50:24,954 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.640  |     0.340\n",
      "2025-05-05 18:50:24,957 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.881  |     0.604\n",
      "2025-05-05 18:50:24,961 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.902  |     0.611\n",
      "2025-05-05 18:50:24,964 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.860  |     0.597\n",
      "2025-05-05 18:50:24,970 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.881  |     0.604\n",
      "2025-05-05 18:50:24,973 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.902  |     0.611\n",
      "2025-05-05 18:50:24,976 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.860  |     0.597\n",
      "2025-05-05 18:50:24,980 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.680  |     0.381\n",
      "2025-05-05 18:50:24,982 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.725  |     0.433\n",
      "2025-05-05 18:50:24,985 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.640  |     0.340\n",
      "2025-05-05 18:50:24,989 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 18:50:24,993 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.455  |    21.097\n",
      "2025-05-05 18:50:24,997 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 18:50:33,752 - INFO - allennlp.training.trainer - Epoch duration: 0:10:08.585377\n",
      "2025-05-05 18:50:33,754 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:20:38\n",
      "2025-05-05 18:50:33,755 - INFO - allennlp.training.trainer - Epoch 11/29\n",
      "2025-05-05 18:50:33,759 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 18:50:33,761 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 18:50:33,764 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9989b326639420db7432b20c8bcdd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:59:59,552 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8931dfa1ca374d0296f65d23975a7163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:00:20,786 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:00:20,790 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.714  |     0.390\n",
      "2025-05-05 19:00:20,794 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.776  |     0.474\n",
      "2025-05-05 19:00:20,797 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.662  |     0.331\n",
      "2025-05-05 19:00:20,800 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.895  |     0.597\n",
      "2025-05-05 19:00:20,803 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.918  |     0.673\n",
      "2025-05-05 19:00:20,806 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.872  |     0.537\n",
      "2025-05-05 19:00:20,810 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.895  |     0.597\n",
      "2025-05-05 19:00:20,813 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.918  |     0.673\n",
      "2025-05-05 19:00:20,816 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.872  |     0.537\n",
      "2025-05-05 19:00:20,821 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.714  |     0.390\n",
      "2025-05-05 19:00:20,824 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.776  |     0.474\n",
      "2025-05-05 19:00:20,827 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.662  |     0.331\n",
      "2025-05-05 19:00:20,831 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:00:20,833 - INFO - allennlp.training.tensorboard_writer - loss                      |     6.227  |    21.619\n",
      "2025-05-05 19:00:20,836 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:00:29,418 - INFO - allennlp.training.trainer - Epoch duration: 0:09:55.663136\n",
      "2025-05-05 19:00:29,420 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:09:07\n",
      "2025-05-05 19:00:29,422 - INFO - allennlp.training.trainer - Epoch 12/29\n",
      "2025-05-05 19:00:29,424 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:00:29,425 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:00:29,430 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb54504554594fc1bba0cac1d0c3a282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:09:52,908 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0878264daa2a4f20af13218fe5593f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:10:13,685 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:10:13,687 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.736  |     0.407\n",
      "2025-05-05 19:10:13,692 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.768  |     0.504\n",
      "2025-05-05 19:10:13,695 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.706  |     0.342\n",
      "2025-05-05 19:10:13,699 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.907  |     0.609\n",
      "2025-05-05 19:10:13,701 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.924  |     0.652\n",
      "2025-05-05 19:10:13,704 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.892  |     0.571\n",
      "2025-05-05 19:10:13,708 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.907  |     0.609\n",
      "2025-05-05 19:10:13,712 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.924  |     0.652\n",
      "2025-05-05 19:10:13,714 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.892  |     0.571\n",
      "2025-05-05 19:10:13,718 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.736  |     0.407\n",
      "2025-05-05 19:10:13,722 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.768  |     0.504\n",
      "2025-05-05 19:10:13,725 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.706  |     0.342\n",
      "2025-05-05 19:10:13,728 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:10:13,732 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.999  |    23.860\n",
      "2025-05-05 19:10:13,736 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:10:20,532 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 19:10:28,091 - INFO - allennlp.training.trainer - Epoch duration: 0:09:58.668520\n",
      "2025-05-05 19:10:28,092 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:57:55\n",
      "2025-05-05 19:10:28,096 - INFO - allennlp.training.trainer - Epoch 13/29\n",
      "2025-05-05 19:10:28,098 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:10:28,100 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:10:28,102 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c7a7a5deda4723aa87832b741c0c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:19:50,506 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ea8b13f60141d887baf9da95f91e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:20:11,365 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:20:11,368 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.767  |     0.385\n",
      "2025-05-05 19:20:11,370 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.800  |     0.507\n",
      "2025-05-05 19:20:11,375 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.736  |     0.310\n",
      "2025-05-05 19:20:11,377 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.918  |     0.597\n",
      "2025-05-05 19:20:11,379 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.929  |     0.655\n",
      "2025-05-05 19:20:11,383 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.908  |     0.549\n",
      "2025-05-05 19:20:11,387 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.918  |     0.597\n",
      "2025-05-05 19:20:11,391 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.929  |     0.655\n",
      "2025-05-05 19:20:11,395 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.908  |     0.549\n",
      "2025-05-05 19:20:11,397 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.767  |     0.385\n",
      "2025-05-05 19:20:11,401 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.800  |     0.507\n",
      "2025-05-05 19:20:11,405 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.736  |     0.310\n",
      "2025-05-05 19:20:11,407 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:20:11,409 - INFO - allennlp.training.tensorboard_writer - loss                      |     5.426  |    23.008\n",
      "2025-05-05 19:20:11,413 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:20:19,741 - INFO - allennlp.training.trainer - Epoch duration: 0:09:51.646240\n",
      "2025-05-05 19:20:19,743 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:46:46\n",
      "2025-05-05 19:20:19,745 - INFO - allennlp.training.trainer - Epoch 14/29\n",
      "2025-05-05 19:20:19,747 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:20:19,749 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:20:19,751 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051c87c7b404bcbbb6c637383b0082b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:29:45,081 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff4e1cb72004a40a78a8e069499a2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:30:07,827 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:30:07,829 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.787  |     0.414\n",
      "2025-05-05 19:30:07,833 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.829  |     0.422\n",
      "2025-05-05 19:30:07,837 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.749  |     0.407\n",
      "2025-05-05 19:30:07,840 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.930  |     0.626\n",
      "2025-05-05 19:30:07,842 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.944  |     0.666\n",
      "2025-05-05 19:30:07,845 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.917  |     0.590\n",
      "2025-05-05 19:30:07,850 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.930  |     0.626\n",
      "2025-05-05 19:30:07,853 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.944  |     0.666\n",
      "2025-05-05 19:30:07,856 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.917  |     0.590\n",
      "2025-05-05 19:30:07,859 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.787  |     0.414\n",
      "2025-05-05 19:30:07,861 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.829  |     0.422\n",
      "2025-05-05 19:30:07,865 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.749  |     0.407\n",
      "2025-05-05 19:30:07,868 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:30:07,870 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.737  |    19.983\n",
      "2025-05-05 19:30:07,872 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:30:14,847 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs\\TJ - Overall Dataset\\seed_4\\weights/best.th'.\n",
      "2025-05-05 19:30:18,973 - INFO - allennlp.training.trainer - Epoch duration: 0:09:59.227594\n",
      "2025-05-05 19:30:18,976 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:35:54\n",
      "2025-05-05 19:30:18,979 - INFO - allennlp.training.trainer - Epoch 15/29\n",
      "2025-05-05 19:30:18,981 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:30:18,982 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:30:18,986 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5676cb96e54422a838d8f930cb0c16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:39:43,135 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0374fa684e174c30915b4d8e9e209530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:40:04,389 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:40:04,393 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.804  |     0.414\n",
      "2025-05-05 19:40:04,397 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.828  |     0.476\n",
      "2025-05-05 19:40:04,400 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.781  |     0.366\n",
      "2025-05-05 19:40:04,403 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.940  |     0.601\n",
      "2025-05-05 19:40:04,407 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.951  |     0.657\n",
      "2025-05-05 19:40:04,413 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.928  |     0.554\n",
      "2025-05-05 19:40:04,417 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.940  |     0.601\n",
      "2025-05-05 19:40:04,419 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.951  |     0.657\n",
      "2025-05-05 19:40:04,422 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.928  |     0.554\n",
      "2025-05-05 19:40:04,425 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.804  |     0.414\n",
      "2025-05-05 19:40:04,428 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.828  |     0.476\n",
      "2025-05-05 19:40:04,431 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.781  |     0.366\n",
      "2025-05-05 19:40:04,435 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:40:04,438 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.310  |    34.051\n",
      "2025-05-05 19:40:04,441 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:40:12,351 - INFO - allennlp.training.trainer - Epoch duration: 0:09:53.371606\n",
      "2025-05-05 19:40:12,352 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:25:04\n",
      "2025-05-05 19:40:12,354 - INFO - allennlp.training.trainer - Epoch 16/29\n",
      "2025-05-05 19:40:12,355 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:40:12,357 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:40:12,360 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758977105728481290725f25364f60e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:49:29,505 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f073af95eb4443288a304d73d08604f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:49:50,199 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2025-05-05 19:49:50,201 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.831  |     0.387\n",
      "2025-05-05 19:49:50,205 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.849  |     0.393\n",
      "2025-05-05 19:49:50,209 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.814  |     0.382\n",
      "2025-05-05 19:49:50,211 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.948  |     0.617\n",
      "2025-05-05 19:49:50,214 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.955  |     0.617\n",
      "2025-05-05 19:49:50,218 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.941  |     0.617\n",
      "2025-05-05 19:49:50,220 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.948  |     0.617\n",
      "2025-05-05 19:49:50,224 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.955  |     0.617\n",
      "2025-05-05 19:49:50,229 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.941  |     0.617\n",
      "2025-05-05 19:49:50,231 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.831  |     0.387\n",
      "2025-05-05 19:49:50,234 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.849  |     0.393\n",
      "2025-05-05 19:49:50,238 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.814  |     0.382\n",
      "2025-05-05 19:49:50,241 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  2210.888  |       N/A\n",
      "2025-05-05 19:49:50,243 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.872  |    32.597\n",
      "2025-05-05 19:49:50,246 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |     0.000  |       N/A\n",
      "2025-05-05 19:49:57,467 - INFO - allennlp.training.trainer - Epoch duration: 0:09:45.113017\n",
      "2025-05-05 19:49:57,469 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:14:14\n",
      "2025-05-05 19:49:57,471 - INFO - allennlp.training.trainer - Epoch 17/29\n",
      "2025-05-05 19:49:57,473 - INFO - allennlp.training.trainer - Worker 0 memory usage: 0B\n",
      "2025-05-05 19:49:57,475 - INFO - allennlp.training.trainer - GPU 0 memory usage: 2.2G\n",
      "2025-05-05 19:49:57,477 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ece5b4aebe4bf993b36f089d445d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:59:12,771 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b72b728903d4d9c8a96fcff21f75309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:59:34,168 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n",
      "2025-05-05 19:59:34,170 - INFO - allennlp.training.checkpointer - loading best weights\n",
      "2025-05-05 19:59:34,809 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
      "2025-05-05 19:59:34,811 - INFO - allennlp.common.util - Metrics: {\n",
      "  \"best_epoch\": 14,\n",
      "  \"peak_worker_0_memory_MB\": 0,\n",
      "  \"peak_gpu_0_memory_MB\": 2210.8876953125,\n",
      "  \"training_duration\": \"2:55:26.102773\",\n",
      "  \"training_start_epoch\": 0,\n",
      "  \"training_epochs\": 16,\n",
      "  \"epoch\": 16,\n",
      "  \"training__None__ner_precision\": 0.9547685086409217,\n",
      "  \"training__None__ner_recall\": 0.9409167367535745,\n",
      "  \"training__None__ner_f1\": 0.9477920152493912,\n",
      "  \"training__MEAN__ner_precision\": 0.9547685086409217,\n",
      "  \"training__MEAN__ner_recall\": 0.9409167367535745,\n",
      "  \"training__MEAN__ner_f1\": 0.9477920152493912,\n",
      "  \"training__None__relation_precision\": 0.8486707566462167,\n",
      "  \"training__None__relation_recall\": 0.8143642072213501,\n",
      "  \"training__None__relation_f1\": 0.831163629080713,\n",
      "  \"training_MEAN__relation_precision\": 0.8486707566462167,\n",
      "  \"training_MEAN__relation_recall\": 0.8143642072213501,\n",
      "  \"training_MEAN__relation_f1\": 0.831163629080713,\n",
      "  \"training_loss\": 3.87152589586409,\n",
      "  \"training_worker_0_memory_MB\": 0.0,\n",
      "  \"training_gpu_0_memory_MB\": 2210.8876953125,\n",
      "  \"validation__None__ner_precision\": 0.6170411985018727,\n",
      "  \"validation__None__ner_recall\": 0.6170411985018727,\n",
      "  \"validation__None__ner_f1\": 0.6170411985018727,\n",
      "  \"validation__MEAN__ner_precision\": 0.6170411985018727,\n",
      "  \"validation__MEAN__ner_recall\": 0.6170411985018727,\n",
      "  \"validation__MEAN__ner_f1\": 0.6170411985018727,\n",
      "  \"validation__None__relation_precision\": 0.39311594202898553,\n",
      "  \"validation__None__relation_recall\": 0.38204225352112675,\n",
      "  \"validation__None__relation_f1\": 0.38749999999999996,\n",
      "  \"validation_MEAN__relation_precision\": 0.39311594202898553,\n",
      "  \"validation_MEAN__relation_recall\": 0.38204225352112675,\n",
      "  \"validation_MEAN__relation_f1\": 0.38749999999999996,\n",
      "  \"validation_loss\": 32.59709647919326,\n",
      "  \"best_validation__None__ner_precision\": 0.6659619450317125,\n",
      "  \"best_validation__None__ner_recall\": 0.5898876404494382,\n",
      "  \"best_validation__None__ner_f1\": 0.6256206554121152,\n",
      "  \"best_validation__MEAN__ner_precision\": 0.6659619450317125,\n",
      "  \"best_validation__MEAN__ner_recall\": 0.5898876404494382,\n",
      "  \"best_validation__MEAN__ner_f1\": 0.6256206554121152,\n",
      "  \"best_validation__None__relation_precision\": 0.4215328467153285,\n",
      "  \"best_validation__None__relation_recall\": 0.40669014084507044,\n",
      "  \"best_validation__None__relation_f1\": 0.41397849462365593,\n",
      "  \"best_validation_MEAN__relation_precision\": 0.4215328467153285,\n",
      "  \"best_validation_MEAN__relation_recall\": 0.40669014084507044,\n",
      "  \"best_validation_MEAN__relation_f1\": 0.41397849462365593,\n",
      "  \"best_validation_loss\": 19.983356815265076\n",
      "}\n",
      "2025-05-05 19:59:34,844 - INFO - allennlp.models.archival - archiving weights and vocabulary to outputs\\TJ - Overall Dataset\\seed_4\\weights\\model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "data_name = \"TJ - Overall Dataset\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "from wrapper import SpanModel\n",
    "\n",
    "# Train SpanModel from scratch\n",
    "random_seed = 4\n",
    "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
    "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
    "\n",
    "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
    "model.fit(path_train, path_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell below is for validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjyiKWjSF7oZ",
    "outputId": "d7475f09-d593-48a9-a708-da3186dd575a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.common.params:error loading _jsonnet (this is expected on Windows), treating C:\\Users\\arsya\\AppData\\Local\\Temp\\tmptl8lnwdd\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x000001A41BF19798>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74205fabbbc4420caf1be5fcc7e9cabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"path_pred\": \"pred.txt\",\n",
      "  \"path_gold\": \"aste/data/triplet_data/TJ - Overall Dataset/test.txt\",\n",
      "  \"precision\": 0.555992141453831,\n",
      "  \"recall\": 0.5062611806797853,\n",
      "  \"score\": 0.5299625468164794\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SpanModel F1 Score\n",
    "import json\n",
    "\n",
    "data_name = \"TJ - Overall Dataset\"\n",
    "\n",
    "path_pred = \"pred.txt\"\n",
    "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
    "model.predict(path_in=path_test, path_out=path_pred)\n",
    "results = model.score(path_pred, path_test)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08b2e55d6325474da282c48e0f959a56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a203635e4a54efd96b85633164a067d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1453b743641b45758303e91bfedafe03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17148c3a40ae4572923f16f249179b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac6bf7c4d7d4fbd8d1c85ec426854db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21dd3d5e1468453ab2f81d5e184a990e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a18149514fe94397abd4bcafd4df0807",
       "IPY_MODEL_c73b50f20f5f4b6c8ccca8e1ec61e738",
       "IPY_MODEL_fb17189f06074ca39d8251ea2ece15f3"
      ],
      "layout": "IPY_MODEL_b379be7248c84e88b3a5bc8362e56e2f"
     }
    },
    "321f61ce086b4ace9260a2d55afbdefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a203635e4a54efd96b85633164a067d",
      "placeholder": "​",
      "style": "IPY_MODEL_c55350fd925a454eae62f9da4ed21962",
      "value": " 466k/466k [00:01&lt;00:00, 503kB/s]"
     }
    },
    "382e7815e6314a798943a7f71eab1dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cc1d9231ee34d33b65a88c4de3b213f",
      "placeholder": "​",
      "style": "IPY_MODEL_9afa9b48d00748739422b2e32763e57d",
      "value": "Downloading: 100%"
     }
    },
    "3c925c25029e4e5a9515b525a819cb31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87d171d5ff4d48bea3781c4185c53cd3",
      "placeholder": "​",
      "style": "IPY_MODEL_ac44150d1166470f944a1d0effeae80b",
      "value": " 433/433 [00:00&lt;00:00, 13.3kB/s]"
     }
    },
    "46568a6cac834c86854b6e41c7e7219a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "542e865145b547ffbe61dec7fb94bab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e57195d10d7414c9f418af4e7eca84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_621130d9d8cf468abe5709a85f07d106",
      "placeholder": "​",
      "style": "IPY_MODEL_1453b743641b45758303e91bfedafe03",
      "value": "Downloading: 100%"
     }
    },
    "621130d9d8cf468abe5709a85f07d106": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e85b97fbf8642ecb7613a8b3646b6dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "808d2ba240c241e9a6989a03c4134a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86c67fc1ac0d47bbace0fe3b6f24c7ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87d171d5ff4d48bea3781c4185c53cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886551311e7d4ee9823ecd34dfc82811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "916c3c664f2348b5b608c368090945ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f00d08843e1a4e9e911a8d9fd11f04d1",
       "IPY_MODEL_de26b5b4f1be42cba2951f528f7715ba",
       "IPY_MODEL_d5d290cde75d463ba7b9b220eed79ca7"
      ],
      "layout": "IPY_MODEL_e30953017bae40849979501dbb4647bc"
     }
    },
    "9463e5ed29e74f05869715f4669d1fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e57195d10d7414c9f418af4e7eca84a",
       "IPY_MODEL_e4bb3941e21d45f2b2327690b4d589bf",
       "IPY_MODEL_321f61ce086b4ace9260a2d55afbdefa"
      ],
      "layout": "IPY_MODEL_94f8b1fb0c764cfa9af078bd238623d4"
     }
    },
    "94f8b1fb0c764cfa9af078bd238623d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "988ec5ae620d4d67b6749ee92a2cb560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9afa9b48d00748739422b2e32763e57d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cc1d9231ee34d33b65a88c4de3b213f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18149514fe94397abd4bcafd4df0807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e85b97fbf8642ecb7613a8b3646b6dc",
      "placeholder": "​",
      "style": "IPY_MODEL_f13fd92805504c0dae5b22e404c256fa",
      "value": "Downloading: 100%"
     }
    },
    "a7aeaf582d15403dbe447d57789b691f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac44150d1166470f944a1d0effeae80b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b379be7248c84e88b3a5bc8362e56e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3f970d5f20748d091d13d1d37e712e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6d16c6d56974ec88f55333b65e0f16a",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e776ac7bd605497395d6cf45648c46e0",
      "value": 433
     }
    },
    "c55350fd925a454eae62f9da4ed21962": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c73b50f20f5f4b6c8ccca8e1ec61e738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86c67fc1ac0d47bbace0fe3b6f24c7ce",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46568a6cac834c86854b6e41c7e7219a",
      "value": 440473133
     }
    },
    "d1d0b028b6c04d59ada3bdfb7efde504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5d290cde75d463ba7b9b220eed79ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_886551311e7d4ee9823ecd34dfc82811",
      "placeholder": "​",
      "style": "IPY_MODEL_988ec5ae620d4d67b6749ee92a2cb560",
      "value": " 232k/232k [00:00&lt;00:00, 209kB/s]"
     }
    },
    "de26b5b4f1be42cba2951f528f7715ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ac6bf7c4d7d4fbd8d1c85ec426854db",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_808d2ba240c241e9a6989a03c4134a33",
      "value": 231508
     }
    },
    "e01ecdf66c3143809825cbbad4aaeebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e30953017bae40849979501dbb4647bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4bb3941e21d45f2b2327690b4d589bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7aeaf582d15403dbe447d57789b691f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1d0b028b6c04d59ada3bdfb7efde504",
      "value": 466062
     }
    },
    "e776ac7bd605497395d6cf45648c46e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f00d08843e1a4e9e911a8d9fd11f04d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08b2e55d6325474da282c48e0f959a56",
      "placeholder": "​",
      "style": "IPY_MODEL_542e865145b547ffbe61dec7fb94bab7",
      "value": "Downloading: 100%"
     }
    },
    "f13fd92805504c0dae5b22e404c256fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f61ea767ae064779b77f7d206a90b765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_382e7815e6314a798943a7f71eab1dbd",
       "IPY_MODEL_b3f970d5f20748d091d13d1d37e712e4",
       "IPY_MODEL_3c925c25029e4e5a9515b525a819cb31"
      ],
      "layout": "IPY_MODEL_17148c3a40ae4572923f16f249179b9b"
     }
    },
    "f6d16c6d56974ec88f55333b65e0f16a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb17189f06074ca39d8251ea2ece15f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd38ef9382a6488a8be23d5bdb1fb533",
      "placeholder": "​",
      "style": "IPY_MODEL_e01ecdf66c3143809825cbbad4aaeebb",
      "value": " 440M/440M [00:07&lt;00:00, 52.8MB/s]"
     }
    },
    "fd38ef9382a6488a8be23d5bdb1fb533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
